{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SKUs = '../Data/productSKUs_Nov2017_do_not_distribute.csv'\n",
    "locations = '../Data/locations_table_Nov2017_Do_Not_Distribute.csv'\n",
    "geography = '../Data/locations_zips_counties_regions3.csv'\n",
    "geography_cleaned = '../Data/geography.csv'\n",
    "sku_shard = '../Data/sku_shard.csv'\n",
    "sku_shard_2 = '../Data/sku_shard_2.csv'\n",
    "sku_shard_3 = '../Data/sku_shard_3.csv'\n",
    "quarantine_csv = '../Data/quarantine.csv'\n",
    "repaired = '../Data/repaired.csv'\n",
    "transactions = '../Data/transactions.csv'\n",
    "fragments = '../Data/fragments.csv'\n",
    "knit_skus = '../Data/knit_skus.csv'\n",
    "# knit_skus_groomed = '../Data/knit_skus_groomed.csv'\n",
    "# scraps = '../Data/scraps.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grab_features(file, delimiter, \n",
    "                  record_number=1,\n",
    "                  print_cols=False, \n",
    "                  print_record=False, \n",
    "                  print_features=False\n",
    "                 ):\n",
    "    \"\"\"\n",
    "    INPUT: CSV data file with headers\n",
    "    OUTPUT: Prints (optionally) \n",
    "       * column names, formatted to copy into SQL CREATE TABLE command\n",
    "       * sample record (values == types for first record) \n",
    "       * features (col -- val for first record)\n",
    "    \"\"\"\n",
    "    with open(file, 'r') as f:\n",
    "        cols = f.readline().split(delimiter)\n",
    "        for _ in range(record_number-1):\n",
    "            f.readline()\n",
    "        record_1 = f.readline().split(delimiter)\n",
    "        if print_cols:\n",
    "            for col in cols:\n",
    "                print col + ' VARCHAR,'\n",
    "        if print_record:\n",
    "            for datum in record_1:\n",
    "                print datum + ' == ' + str(type(datum))\n",
    "        if print_features:\n",
    "            for col, v in zip(cols, record_1):\n",
    "                print col + ' -- ' + v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inspect_line(source_file, line_num, delimiter='\\t', quarantine=False, q_file=None): \n",
    "    with open(source_file, 'r') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if i == line_num:\n",
    "                vals = line.split(delimiter)\n",
    "                print(\"Number of values: {}\\n==========\\n\").format(len(vals))\n",
    "                print(\"Raw text:\\n%r\\n==========\\n\") % line\n",
    "                for i, val in enumerate(vals):\n",
    "                    print \"{}: {}\".format(i, val)\n",
    "                \n",
    "                if quarantine:\n",
    "                    with open(q_file, 'w') as f2:\n",
    "                        f2.write(line)\n",
    "            \n",
    "            elif i > line_num:\n",
    "                f.close()\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id -- 673315\n",
      "wa_seller_org_id -- 757\n",
      "seller_organization_id -- 523\n",
      "wa_inventory_id -- 6034295410008482\n",
      "wa_transaction_id -- 68981023\n",
      "wa_inventory_parent_id -- 6034295410007770\n",
      "wa_seller_location_id -- 593\n",
      "seller_location_id -- 653\n",
      "first_retail_sale_at -- 2017-01-06 02:20:02+00\n",
      "most_recent_retail_sale_at -- 2017-07-24 16:56:47+00\n",
      "wa_retail_location_id -- 868\n",
      "retail_location_id -- 965\n",
      "lowest_retail_unit_price -- 12.33\n",
      "highest_retail_unit_price -- 17.16\n",
      "avg_retail_unit_price -- 16.68\n",
      "unit_weight -- \n",
      "generic_strain_id -- \n",
      "strain_display_name -- mixed\n",
      "user_strain_name -- Mixed\n",
      "strain_type_id -- \n",
      "is_prerolled -- f\n",
      "user_product_description -- Indica Amazeballs\n",
      "total_thc_amount -- 58.73\n",
      "total_cbd_amount -- 1.38\n",
      "total_potency_amount -- 60.11\n",
      "thc_potency_range_id -- 9\n",
      "cbd_potency_range_id -- 2\n",
      "total_potency_range_id -- 9\n",
      "cannabinoid_type_id -- 1\n",
      "unit_weight_range_id -- \n",
      "retail_unit_price_range_id -- 7\n",
      "inventory_type_id -- 30\n",
      "retailer_name -- PAPER AND LEAF\n",
      "generic_sku -- [Marijuana Mix Infused mixed][NA]\n",
      "tight_sku -- [PAPER AND LEAF][Marijuana Mix Infused Mixed][NA]\n",
      "total_retail_sales_amount -- 683.76\n",
      "total_retail_sales_weight -- 41.00\n",
      "total_retail_sales_units -- 41.00\n",
      "seller_price -- 336.00\n",
      "seller_unit_price -- 7.00\n",
      "wa_transfer_original_id -- 68946021\n",
      "seller_transfer_date -- 2017-01-04 00:00:00+00\n",
      "seller_units -- 48.00\n",
      "buyer_location_id -- 965\n",
      "wa_buyer_location_id -- 868\n",
      "wa_inventory_transfer_id\n",
      " -- 2651464\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grab_features(transactions, '\\t', record_number=21, print_features=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of values: 64\n",
      "==========\n",
      "\n",
      "Raw text:\n",
      "'orgid,orgid_dupl,locationid,Unnamed,name,address1,address2,city,state,zip,deleted,locationtype,licensenum,id,locationexp,locationissue,status,districtcode,loclatitude,loclongitude,mailaddress1,mailaddress2,mailcity,mailstate,mailzip,locubi,producer,processor,retail,transactionid,transactionid_original,fifteenday_end,delete_time,code,county,pop2014,pop2010,sqmi,km2,Zip Code,City,County,ZIP Code Tabulation Area,Total Population, 2010,Population Density (Persons / Square Mile), 2010,Total Housing Units, 2010,Occupied Housing Units, 2010,Vacant Housing Units, 2010,Occupancy Rate (%), 2010,Vacancy Rate (%), 2010,Land Area (Square Miles), 2010,Total Area (Square Miles), 2010,Water Area (%), 2010,Region\\r\\n'\n",
      "==========\n",
      "\n",
      "0: orgid\n",
      "1: orgid_dupl\n",
      "2: locationid\n",
      "3: Unnamed\n",
      "4: name\n",
      "5: address1\n",
      "6: address2\n",
      "7: city\n",
      "8: state\n",
      "9: zip\n",
      "10: deleted\n",
      "11: locationtype\n",
      "12: licensenum\n",
      "13: id\n",
      "14: locationexp\n",
      "15: locationissue\n",
      "16: status\n",
      "17: districtcode\n",
      "18: loclatitude\n",
      "19: loclongitude\n",
      "20: mailaddress1\n",
      "21: mailaddress2\n",
      "22: mailcity\n",
      "23: mailstate\n",
      "24: mailzip\n",
      "25: locubi\n",
      "26: producer\n",
      "27: processor\n",
      "28: retail\n",
      "29: transactionid\n",
      "30: transactionid_original\n",
      "31: fifteenday_end\n",
      "32: delete_time\n",
      "33: code\n",
      "34: county\n",
      "35: pop2014\n",
      "36: pop2010\n",
      "37: sqmi\n",
      "38: km2\n",
      "39: Zip Code\n",
      "40: City\n",
      "41: County\n",
      "42: ZIP Code Tabulation Area\n",
      "43: Total Population\n",
      "44:  2010\n",
      "45: Population Density (Persons / Square Mile)\n",
      "46:  2010\n",
      "47: Total Housing Units\n",
      "48:  2010\n",
      "49: Occupied Housing Units\n",
      "50:  2010\n",
      "51: Vacant Housing Units\n",
      "52:  2010\n",
      "53: Occupancy Rate (%)\n",
      "54:  2010\n",
      "55: Vacancy Rate (%)\n",
      "56:  2010\n",
      "57: Land Area (Square Miles)\n",
      "58:  2010\n",
      "59: Total Area (Square Miles)\n",
      "60:  2010\n",
      "61: Water Area (%)\n",
      "62:  2010\n",
      "63: Region\r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inspect_line(geography_cleaned, 0, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_fragments(file, record_len=46, delimiter='\\t'):\n",
    "    count = 0\n",
    "    with open(file, 'r') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            vals = line.split(delimiter)\n",
    "            if len(vals) != record_len:\n",
    "                print \"Line number: {} Values: {}\".format(i, len(vals))\n",
    "                count += 1\n",
    "    print(\"Total fragments: {}\".format(count))\n",
    "    \n",
    "def write_shard(read_file, write_file, num_records=100):\n",
    "    f1 = open(read_file, 'r')\n",
    "    f2 = open(write_file, 'w')\n",
    "    for i, line in enumerate(f1):\n",
    "        if i <= num_records + 1:\n",
    "            f2.write(line)\n",
    "        else: break\n",
    "    f1.close()\n",
    "    f2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def close_quotes_in_prod_descr(source, write_f, fragment_f):    \n",
    "    counter = 0\n",
    "    fragments = 0\n",
    "    f1 = open(source, 'r')\n",
    "    f2 = open(write_f, 'w')\n",
    "    f3 = open(fragment_f, 'w')\n",
    "    for line in f1:\n",
    "        parsed = line.split('\\t')\n",
    "        if len(parsed) != 46:\n",
    "            f3.write(line)\n",
    "            fragments += 1\n",
    "            continue\n",
    "        else:\n",
    "            prod_desc = parsed[21]\n",
    "\n",
    "        if prod_desc.count('\"') % 2 == 0:\n",
    "            f2.write(line)\n",
    "        else:\n",
    "            fixed = prod_desc + '\"'\n",
    "            parsed[21] = fixed\n",
    "            patched = '\\t'.join(parsed)\n",
    "            f2.write(patched)\n",
    "            counter += 1\n",
    "    \n",
    "    f1.close()\n",
    "    f2.close()\n",
    "    f3.close()\n",
    "    print(\n",
    "    \"\"\"\\nProcessing complete\n",
    "    Records repaired: {}\n",
    "    Fragments written: {}\"\"\"\n",
    "    ).format(counter, fragments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def knit_fragments(read_f, write_f, delimiter='\\t'):\n",
    "    \"\"\"Takes in a csv file of sequential record fragments, fuses them and writes\n",
    "    complete records to file.\n",
    "    \"\"\"\n",
    "    f1 = open(read_f, 'r')\n",
    "    f2 = open(write_f, 'w')\n",
    "    counter = 0\n",
    "    frag_22s = []\n",
    "    frag_25s = []\n",
    "    frag_19s = []\n",
    "    frag_17s = []\n",
    "    frag_12s = []\n",
    "    for line in f1: # sort fragments into lists by frag-length\n",
    "        if len(line.strip().split(delimiter)) == 22:\n",
    "            frag_22s.append(line.strip())\n",
    "        if len(line.strip().split(delimiter)) == 25:\n",
    "            frag_25s.append(line.strip())\n",
    "        if len(line.strip().split(delimiter)) == 19:\n",
    "            frag_19s.append(line.strip())\n",
    "        if len(line.strip().split(delimiter)) == 17:\n",
    "            frag_17s.append(line.strip())\n",
    "        if len(line.strip().split(delimiter)) == 12:\n",
    "            frag_12s.append(line.strip())\n",
    "            \n",
    "    doubles = zip(frag_22s, frag_25s)\n",
    "    triples = zip(frag_19s, frag_17s, frag_12s)\n",
    "    \n",
    "    for tup in doubles:\n",
    "        f2.write(''.join(tup) + '\\n')\n",
    "        counter += 1\n",
    "    for tup in triples:\n",
    "        f2.write(''.join(tup) + '\\n')\n",
    "        counter += 1\n",
    "    \n",
    "    f1.close()\n",
    "    f2.close()\n",
    "    print(\"Total records recovered and written: {}\").format(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "specimen_cols = ',Unnamed: 0,orgid,locationid,name,address1,address2,city,state,zip,deleted,locationtype,licensenum,id,locationexp,locationissue,status,districtcode,loclatitude,loclongitude,mailaddress1,mailaddress2,mailcity,mailstate,mailzip,locubi,producer,processor,retail,transactionid,transactionid_original,fifteenday_end,delete_time,code,county,pop2014,pop2010,sqmi,km2,Zip Code,City,County,ZIP Code Tabulation Area,\"Total Population, 2010\",\"Population Density (Persons / Square Mile), 2010\",\"Total Housing Units, 2010\",\"Occupied Housing Units, 2010\",\"Vacant Housing Units, 2010\",\"Occupancy Rate (%), 2010\",\"Vacancy Rate (%), 2010\",\"Land Area (Square Miles), 2010\",\"Total Area (Square Miles), 2010\",\"Water Area (%), 2010\",Region\\r\\n'\n",
    "specimen = '260,260,196,1,SATURN GROUP,13215 SE 30TH ST,,bellevue,WA,98005,0,6,412112,400,1509519599,1497941999,ACTIVE (ISSUED),7J,47.583253,-122.163329,13215 SE 30TH ST,,BELLEVUE,WA,980054402,603344149,1,1,,101005715,304712,1411114512,,Code,King,\"136,426\",\"122,363\",33.48,86.7,98005,Bellevue,King,98005,\"17,714\",\"2,361.29\",\"8,070\",\"7,539\",531,93.42,6.58,7.5,7.51,0.09,405 Corridor\\r\\n'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# segment = ',Unnamed: 0,orgid,locationid,'\n",
    "# revised_seg = 'orgid, orgid_dupl, locationid, Unnamed,'\n",
    "\n",
    "def remove_quotes(read_f, write_f):\n",
    "    # Remove double-quotes from compound fields in source csv and writes lines to new csv.\n",
    "    segment = ',Unnamed: 0,orgid,locationid,'\n",
    "    revised_seg = 'orgid,orgid_dupl,locationid,Unnamed,'\n",
    "    f1 = open(read_f ,'r')\n",
    "    f2 = open(write_f, 'w')\n",
    "    counter = 0\n",
    "    for line in f1:\n",
    "        cleaned = line.replace('\"', '').replace(segment, revised_seg)#.rstrip()\n",
    "        f2.write(cleaned)\n",
    "        counter += 1\n",
    "    print('Processing complete. {} lines written to file.').format(counter)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "remove_quotes(geography, geography_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grab_features(geography_cleaned, ',', record_number=5, print_features=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iterator = 0"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "line3 = '39,39,226,1,GAIA INDUSTRIES,17022 FROHNING RD,,monroe,WA,98272,0,5,412232,175,1525157999,1493967599,ACTIVE (ISSUED),7G,47.823599,-122.002588,1429 AVENUE D # 225,,SNOHOMISH,WA,982901742,603297007,1,1,,91567331,121565,1401880503,,Code,Snohomish,17,899,17,304,6.05,15.7,98272,Monroe,Snohomish,98272,27,942,255.69,9,398,8,822,576,93.87,6.13,109.28,110.05,0.7,405 Corridor\\n'\n",
    "line2 = '59,59,210,1,COPPERHEAD FARM,105 MILL ST,,prescott,WA,99348,0,5,412078,196,1504249199,1472885999,ACTIVE (ISSUED),7O,46.2986019,-118.308488,103 MILL ST,,PRESCOTT,WA,993489762,603324540,1,1,0,61598569,121606,1403694900,,Code,Walla Walla,309,318,0.4,1,99348,Prescott,Walla Walla,99348,1,364,2.63,512,441,71,86.13,13.87,519.6,527.42,1.48,405 Corridor\\n'\n",
    "line200 = '1310,1310,1315,1,WEST CHOICE,2805 6TH AVE,,tacoma,WA,98406,1,8,409509,1706,1488355199,1456214399,CLOSED (PERMANENT),7V,47.25568,-122.472924,PO BOX 2766,,GIG HARBOR,WA,983354766,603479772,0,0,1,61598569,31019537,1457585999,1467879311,First,Pierce,205,159,198,397,49.73,128.8,98406,Tacoma,Pierce,98406,21,610,5,063.61,10,220,9,562,658,93.56,6.44,4.27,4.67,8.71,Greater Tacoma\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lst_3 = line3.split(',')\n",
    "lst_2 = line2.split(',')\n",
    "lst_200 = line200.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(lst_200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{54, 55, 56, 57, 58, 59, 60, 61, 62, 64}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line_lengths = []\n",
    "with open(geography_cleaned, 'r') as f:\n",
    "    for l in f:\n",
    "        line_lengths.append(len(l.split(',')))\n",
    "set(line_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54: 57\n",
      "55: 88\n",
      "56: 83\n",
      "57: 150\n",
      "58: 38\n",
      "59: 738\n",
      "60: 772\n",
      "61: 184\n",
      "62: 5\n",
      "64: 1\n"
     ]
    }
   ],
   "source": [
    "set_len = set(line_lengths)\n",
    "for length in sorted(list(set_len)):\n",
    "    print\"{}: {}\".format(length, line_lengths.count(length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_first_line_of_length(read_f, line_len):  \n",
    "    with open(read_f, 'r') as f:\n",
    "        for i, spec in enumerate(f):\n",
    "            if len(spec.split(',')) == line_len:\n",
    "                print('Line number: {}\\nRaw Text:\\n{}').format(i, spec)\n",
    "                f.close()\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line number: 55\n",
      "Raw Text:\n",
      "589,589,905,1,LOCAL ROOTS MARIJUANA,212 W WINESAP RD STE 101, 102,,bothell,WA,98012,0,10,415222,738,1509519599,1499497199,ACTIVE (ISSUED),3H,47.8235207,-122.2357949,212 W WINESAP RD STE 101,,BOTHELL,WA,980120000,603441961,,,1,105024514,2905914,1428826506,,Code,King,36,567,33,505,12.1,31.3,98012,Bothell,Snohomish,98012,51,136,3,337.63,20,580,19,448,1,132,94.5,5.5,15.32,15.34,0.1,405 Corridor\r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_first_line_of_length(geography_cleaned, 62)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lens = []\n",
    "for l in lengths:\n",
    "    lens.append(l)\n",
    "    \n",
    "sorted(lens), len(lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iterator += 1\n",
    "iterator + 1, inspect_line(fragments, iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_shard(SKUs, sku_shard_3, num_records=77001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_line(transactions, 2)#, quarantine=True, q_file=quarantine_csv) \n",
    "# Line of bum record: 77983, 125\n",
    "# One that works with apostrophe: 73588"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bad file:\n",
    "'758403\\t968\\t685\\t6033539070000652\\t29568233\\t6033490610000803\\t856\\t847\\t2016-04-14 16:33:13+00\\t2016-05-04 17:19:45+00\\t408\\t440\\t21.99\\t54.98\\t26.24\\t7.00\\t116\\tSFV OG\\tSFV OG\\t3\\tf\\t\"7gx50 sfv \\'\"smalls: 0807.  22.11/.04   cannarex\"\\t22.11\\t0.04\\t22.15\\t6\\t\\t6\\t1\\t2\\t10\\t24\\tCANNAREX\\t[Usable Marijuana SFV OG][7.0g]\\t[CANNAREX][Usable Marijuana SFV OG][7.0g]\\t1313.34\\t350.00\\t50.00\\t612.50\\t12.25\\t29528934\\t2016-04-09 00:00:00+00\\t50.00\\t440\\t408\\t1105398\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf # pre_rolled\n",
    "\"7gx50 sfv \\'\"smalls: 0807. 22.11/.04 cannarex\"\" # product description\n",
    "22.11 # total_thc_amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "close_quotes_in_prod_descr(SKUs, transactions, fragments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(quarantine_csv, 'r') as f:\n",
    "    contents = f.read()\n",
    "contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q = '673421\\t1309\\t969\\t6034748420019119\\t107535332\\t6034748420017464\\t1170\\t1181\\t2017-07-19 23:11:40+00\\t2017-07-31 23:01:36+00\\t250\\t205\\t26.88\\t26.88\\t26.88\\t\\t1\\tBlue Dream\\tBlue Dream\\t3\\tf\\t\"PH Blue Dream 7464 .5g Clarity6033453330010001\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(q.split('\\t'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "3043190 - 3032996"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
